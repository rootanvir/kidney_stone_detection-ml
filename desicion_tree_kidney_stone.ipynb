{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Oj5pMF7bZ0BH"
      },
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Step 1: Import Libraries\n",
        "# ================================\n",
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Step 2: Mount Google Drive\n",
        "# ================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25IiMDC5aKMF",
        "outputId": "710f71d0-f8a9-4e30-a730-66a1f368984f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Step 3: Extract Dataset\n",
        "# ================================\n",
        "zip_path = \"/content/drive/MyDrive/kindey_stone_dataset.zip\"\n",
        "extract_path = \"/content/dataset\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "train_dir = \"/content/dataset/kindey_stone_dataset/train\"\n",
        "val_dir   = \"/content/dataset/kindey_stone_dataset/val\""
      ],
      "metadata": {
        "id": "qI4Rd9p6aVV_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Step 4: Load Images & Flatten\n",
        "# ================================\n",
        "def load_images(folder):\n",
        "    X, y = [], []\n",
        "    classes = os.listdir(folder)\n",
        "    class_map = {cls:i for i, cls in enumerate(classes)}\n",
        "    for cls in classes:\n",
        "        cls_folder = os.path.join(folder, cls)\n",
        "        for file in os.listdir(cls_folder):\n",
        "            img_path = os.path.join(cls_folder, file)\n",
        "            img = load_img(img_path, target_size=(64, 64))\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            X.append(img_array.flatten())\n",
        "            y.append(class_map[cls])\n",
        "    return np.array(X), np.array(y), class_map\n",
        "\n",
        "X_train, y_train, class_map = load_images(train_dir)\n",
        "X_val, y_val, _ = load_images(val_dir)"
      ],
      "metadata": {
        "id": "ZCt1XKntanEd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Step 5: Train Decision Tree in Batches (Verbose Simulation)\n",
        "# ================================\n",
        "batch_size = 1000\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Split training data into batches\n",
        "for i in range(0, len(X_train), batch_size):\n",
        "    X_batch = X_train[i:i+batch_size]\n",
        "    y_batch = y_train[i:i+batch_size]\n",
        "\n",
        "    # Decision Tree doesn't support partial fit, so we re-fit each batch\n",
        "    dt.fit(X_batch, y_batch)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    y_val_pred = dt.predict(X_val)\n",
        "    acc = accuracy_score(y_val, y_val_pred)\n",
        "    print(f\"Processed {i+len(X_batch)}/{len(X_train)} samples - Validation Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxoD__8ebHTo",
        "outputId": "d0346370-6633-4c6d-824e-25f9eeac0dfb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 2000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 3000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 4000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 5000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 6000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 7000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 8000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 9000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 10000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 11000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 12000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 13000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 14000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 15000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 16000/35457 samples - Validation Accuracy: 0.4688\n",
            "Processed 17000/35457 samples - Validation Accuracy: 0.6165\n",
            "Processed 18000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 19000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 20000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 21000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 22000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 23000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 24000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 25000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 26000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 27000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 28000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 29000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 30000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 31000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 32000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 33000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 34000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 35000/35457 samples - Validation Accuracy: 0.5312\n",
            "Processed 35457/35457 samples - Validation Accuracy: 0.5312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Step 6: Final Evaluation\n",
        "# ================================\n",
        "y_pred = dt.predict(X_val)\n",
        "print(\"\\n✅ Final Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred, target_names=list(class_map.keys())))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKACu4sLfhD1",
        "outputId": "4984ec25-05c4-46ee-8643-d07438660aab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Final Validation Accuracy: 0.5312128418549346\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       Stone       0.00      0.00      0.00      1577\n",
            "   Non-Stone       0.53      1.00      0.69      1787\n",
            "\n",
            "    accuracy                           0.53      3364\n",
            "   macro avg       0.27      0.50      0.35      3364\n",
            "weighted avg       0.28      0.53      0.37      3364\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Step 7: Save Decision Tree Model\n",
        "# ================================\n",
        "joblib.dump(dt, \"/content/dt_kidney_stone_verbose.pkl\")\n",
        "print(\"✅ Decision Tree model saved at /content/dt_kidney_stone_verbose.pkl\")"
      ],
      "metadata": {
        "id": "KnRHbr3vfsCk",
        "outputId": "48936718-d7fd-4013-b503-f299150a0f71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Decision Tree model saved at /content/dt_kidney_stone_verbose.pkl\n"
          ]
        }
      ]
    }
  ]
}